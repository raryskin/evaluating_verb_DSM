{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c1ded2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "import os\n",
    "from collections import Counter\n",
    "from scipy.interpolate import interp1d\n",
    "from nltk.corpus import verbnet\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import classification_report\n",
    "tqdm.pandas()\n",
    "scale_converter = interp1d([0,6],[0,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c1f60a",
   "metadata": {},
   "source": [
    "# WordNet demo\n",
    "\n",
    "Choose some words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e8a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = \"turn\"\n",
    "word2 = \"twist\"\n",
    "word3 = \"jump\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e1510",
   "metadata": {},
   "source": [
    "Synsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d61cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synsets for turn\n",
      "[Synset('bend.n.01'), Synset('turn.n.02'), Synset('turn.n.03'), Synset('turn.n.04'), Synset('turning.n.04'), Synset('turn.n.06'), Synset('twist.n.13'), Synset('go.n.01'), Synset('turn.n.09'), Synset('act.n.04'), Synset('turn.n.11'), Synset('turn.n.12'), Synset('turn.v.01'), Synset('change_state.v.01'), Synset('become.v.02'), Synset('turn.v.04'), Synset('change_by_reversal.v.01'), Synset('turn.v.06'), Synset('turn.v.07'), Synset('turn.v.08'), Synset('turn.v.09'), Synset('turn.v.10'), Synset('turn.v.11'), Synset('plow.v.01'), Synset('turn.v.13'), Synset('turn.v.14'), Synset('twist.v.10'), Synset('turn.v.16'), Synset('turn.v.17'), Synset('turn.v.18'), Synset('turn.v.19'), Synset('turn.v.20'), Synset('flex.v.05'), Synset('turn.v.22'), Synset('turn.v.23'), Synset('call_on.v.01'), Synset('sour.v.01'), Synset('turn.v.26')]\n",
      "\n",
      "Synsets for turn filtered just to verb POS\n",
      "[Synset('turn.v.01'), Synset('change_state.v.01'), Synset('become.v.02'), Synset('turn.v.04'), Synset('change_by_reversal.v.01'), Synset('turn.v.06'), Synset('turn.v.07'), Synset('turn.v.08'), Synset('turn.v.09'), Synset('turn.v.10'), Synset('turn.v.11'), Synset('plow.v.01'), Synset('turn.v.13'), Synset('turn.v.14'), Synset('twist.v.10'), Synset('turn.v.16'), Synset('turn.v.17'), Synset('turn.v.18'), Synset('turn.v.19'), Synset('turn.v.20'), Synset('flex.v.05'), Synset('turn.v.22'), Synset('turn.v.23'), Synset('call_on.v.01'), Synset('sour.v.01'), Synset('turn.v.26')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Synsets for\", word1)\n",
    "print(wn.synsets(word1))\n",
    "print()\n",
    "print(\"Synsets for\",word1,\"filtered just to verb POS\")\n",
    "print(wn.synsets(word1, pos = wn.VERB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22702d0",
   "metadata": {},
   "source": [
    "Just for now, selecting the first synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0c89a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_syn = wn.synsets(word1, pos = wn.VERB)[0]\n",
    "w2_syn = wn.synsets(word2, pos = wn.VERB)[0]\n",
    "w3_syn = wn.synsets(word3, pos = wn.VERB)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ba3a2",
   "metadata": {},
   "source": [
    "# Verb frames:\n",
    "\n",
    "For the synsets' lemma, it has a specific amount of verb frames. It generally seems to be the same amount per synset for each lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519508d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma('turn.v.01.turn') [1, 2, 4] 3\n",
      "Something turn | Somebody turn | Something is turning PP\n",
      "------------------------------\n",
      "Lemma('writhe.v.01.writhe') [1, 2] 2\n",
      "Something writhe | Somebody writhe\n",
      "Lemma('writhe.v.01.wrestle') [1, 2] 2\n",
      "Something wrestle | Somebody wrestle\n",
      "Lemma('writhe.v.01.wriggle') [1, 2] 2\n",
      "Something wriggle | Somebody wriggle\n",
      "Lemma('writhe.v.01.worm') [1, 2] 2\n",
      "Something worm | Somebody worm\n",
      "Lemma('writhe.v.01.squirm') [1, 2] 2\n",
      "Something squirm | Somebody squirm\n",
      "Lemma('writhe.v.01.twist') [1, 2] 2\n",
      "Something twist | Somebody twist\n",
      "------------------------------\n",
      "Lemma('jump.v.01.jump') [1, 2, 22] 3\n",
      "Something jump | Somebody jump | Somebody jump PP\n",
      "Lemma('jump.v.01.leap') [1, 2, 22] 3\n",
      "Something leap | Somebody leap | Somebody leap PP\n",
      "Lemma('jump.v.01.bound') [1, 2, 22] 3\n",
      "Something bound | Somebody bound | Somebody bound PP\n",
      "Lemma('jump.v.01.spring') [1, 2, 22] 3\n",
      "Something spring | Somebody spring | Somebody spring PP\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for lemma in w1_syn.lemmas():\n",
    "    print(lemma, lemma.frame_ids(), len(lemma.frame_ids()))\n",
    "    print(\" | \".join(lemma.frame_strings()))\n",
    "print(\"------------------------------\")\n",
    "\n",
    "for lemma in w2_syn.lemmas():\n",
    "    print(lemma, lemma.frame_ids(), len(lemma.frame_ids()))\n",
    "    print(\" | \".join(lemma.frame_strings()))\n",
    "print(\"------------------------------\")\n",
    "\n",
    "for lemma in w3_syn.lemmas():\n",
    "    print(lemma, lemma.frame_ids(), len(lemma.frame_ids()))\n",
    "    print(\" | \".join(lemma.frame_strings()))\n",
    "print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880368de",
   "metadata": {},
   "source": [
    "# Multiple similarity metrics: \n",
    "\n",
    "Path similarity\n",
    "\n",
    "Leacock-Chodorow Similarity\n",
    "\n",
    "Wu-Palmer similarity\n",
    "\n",
    "Resnik similarity\n",
    "\n",
    "Jiang-Conrath similarity\n",
    "\n",
    "Lin Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f0f84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path similarity: 0.3333333333333333\n",
      "Lch similarity: 2.159484249353372\n",
      "Wup similarity: 0.3333333333333333\n",
      "Res similarity: 4.692755582239643\n",
      "JCN similarity: 0.12831564565996478\n",
      "Lin similarity: 0.546342873109817\n"
     ]
    }
   ],
   "source": [
    "print(\"Path similarity:\", w1_syn.path_similarity(w2_syn))\n",
    "\n",
    "print(\"Lch similarity:\",w1_syn.lch_similarity(w2_syn))\n",
    "\n",
    "print(\"Wup similarity:\",w1_syn.wup_similarity(w2_syn))\n",
    "\n",
    "print(\"Res similarity:\",w1_syn.res_similarity(w2_syn, brown_ic))\n",
    "\n",
    "print(\"JCN similarity:\",w1_syn.jcn_similarity(w2_syn, brown_ic))\n",
    "\n",
    "print(\"Lin similarity:\",w1_syn.lin_similarity(w2_syn, brown_ic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c44707",
   "metadata": {},
   "source": [
    "# VerbNet:\n",
    "\n",
    "http://verbs.colorado.edu/~kipper/Papers/dissertation.pdf\n",
    "\n",
    "http://verbs.colorado.edu/verb-index/VerbNet_Guidelines.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5091b964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['give-13.1-1']\n",
      "lemmas ['give', 'hock', 'rent', 'sell', 'lease', 'pawn']\n",
      "vnclass <Element 'VNSUBCLASS' at 0x7f4eded4ea90>\n",
      "Sub-classes []\n"
     ]
    }
   ],
   "source": [
    "a = verbnet.classids(lemma = \"give\")\n",
    "print(a)\n",
    "\n",
    "print(\"lemmas\",verbnet.lemmas(a[0]))\n",
    "\n",
    "print(\"vnclass\",verbnet.vnclass(a[0]))\n",
    "\n",
    "print(\"Sub-classes\", verbnet.subclasses(verbnet.vnclass(a[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd70c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classid(verb):\n",
    "    # print(verb)\n",
    "    classid = verbnet.classids(lemma = verb)\n",
    "    # print(classid)\n",
    "    return classid\n",
    "    \n",
    "def get_lemmas(verb):\n",
    "    classid = get_classid(verb)\n",
    "    if len(classid) > 0:\n",
    "        lemmas = verbnet.lemmas(classid[0])\n",
    "        return lemmas\n",
    "    else:\n",
    "        return \"-1\"\n",
    "\n",
    "def get_frames(verb):\n",
    "    classid = get_classid(verb)\n",
    "    if len(classid) > 0:\n",
    "        frames = []\n",
    "        for item in verbnet.frames(classid[0]):\n",
    "            # print(item)\n",
    "            frames.append(item[\"description\"][\"primary\"])\n",
    "        return frames\n",
    "    else:\n",
    "        return [\"-1\"]\n",
    "\n",
    "def get_unique_frames(classid):\n",
    "    frames = []\n",
    "    for item in verbnet.frames(classid[0]):\n",
    "        # print(item)\n",
    "        frames.append(item[\"description\"][\"primary\"])\n",
    "    return pd.unique(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c372c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1 = get_classid(\"catch\")\n",
    "# print(step1)\n",
    "\n",
    "# step2a = get_lemmas(step1)\n",
    "# print(step2a)\n",
    "\n",
    "# step2b = get_frames(step1)\n",
    "# print(step2b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a677f342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example : He leased the car for $200 a week.\n",
      "\n",
      "description : {'primary': 'NP-PP', 'secondary': 'Asset-PP'}\n",
      "\n",
      "syntax : [{'pos_tag': 'NP', 'modifiers': {'value': 'Agent', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'VERB', 'modifiers': {'value': '', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'NP', 'modifiers': {'value': 'Theme', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'PREP', 'modifiers': {'value': 'for at', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'NP', 'modifiers': {'value': 'Asset', 'selrestrs': [], 'synrestrs': []}}]\n",
      "\n",
      "semantics : [{'predicate_value': 'has_possession', 'arguments': [{'type': 'Event', 'value': 'start(E)'}, {'type': 'ThemRole', 'value': 'Agent'}, {'type': 'ThemRole', 'value': 'Theme'}]}, {'predicate_value': 'has_possession', 'arguments': [{'type': 'Event', 'value': 'end(E)'}, {'type': 'ThemRole', 'value': '?Recipient'}, {'type': 'ThemRole', 'value': 'Theme'}]}, {'predicate_value': 'has_possession', 'arguments': [{'type': 'Event', 'value': 'start(E)'}, {'type': 'ThemRole', 'value': '?Recipient'}, {'type': 'ThemRole', 'value': 'Asset'}]}, {'predicate_value': 'has_possession', 'arguments': [{'type': 'Event', 'value': 'end(E)'}, {'type': 'ThemRole', 'value': 'Agent'}, {'type': 'ThemRole', 'value': 'Asset'}]}, {'predicate_value': 'transfer', 'arguments': [{'type': 'Event', 'value': 'during(E)'}, {'type': 'ThemRole', 'value': 'Theme'}]}]\n",
      "\n",
      "\n",
      "--------------------------\n",
      "example : I leased the car to my friend for $5 a month.\n",
      "\n",
      "description : {'primary': 'NP-PP-PP', 'secondary': 'Recipient-PP Asset-PP'}\n",
      "\n",
      "syntax : [{'pos_tag': 'NP', 'modifiers': {'value': 'Agent', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'VERB', 'modifiers': {'value': '', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'NP', 'modifiers': {'value': 'Theme', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'PREP', 'modifiers': {'value': 'to', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'NP', 'modifiers': {'value': 'Recipient', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'PREP', 'modifiers': {'value': 'at for on', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'NP', 'modifiers': {'value': 'Asset', 'selrestrs': [], 'synrestrs': []}}]\n",
      "\n",
      "semantics : [{'predicate_value': 'has_possession', 'arguments': [{'type': 'Event', 'value': 'start(E)'}, {'type': 'ThemRole', 'value': 'Agent'}, {'type': 'ThemRole', 'value': 'Theme'}]}, {'predicate_value': 'has_possession', 'arguments': [{'type': 'Event', 'value': 'end(E)'}, {'type': 'ThemRole', 'value': 'Recipient'}, {'type': 'ThemRole', 'value': 'Theme'}]}, {'predicate_value': 'has_possession', 'arguments': [{'type': 'Event', 'value': 'start(E)'}, {'type': 'ThemRole', 'value': 'Recipient'}, {'type': 'ThemRole', 'value': 'Asset'}]}, {'predicate_value': 'has_possession', 'arguments': [{'type': 'Event', 'value': 'end(E)'}, {'type': 'ThemRole', 'value': 'Agent'}, {'type': 'ThemRole', 'value': 'Asset'}]}, {'predicate_value': 'transfer', 'arguments': [{'type': 'Event', 'value': 'during(E)'}, {'type': 'ThemRole', 'value': 'Theme'}]}]\n",
      "\n",
      "\n",
      "--------------------------\n",
      "example : I leased him the car for $250 a month.\n",
      "\n",
      "description : {'primary': 'NP-PP', 'secondary': 'Asset-PP'}\n",
      "\n",
      "syntax : [{'pos_tag': 'NP', 'modifiers': {'value': 'Agent', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'VERB', 'modifiers': {'value': '', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'NP', 'modifiers': {'value': 'Recipient', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'NP', 'modifiers': {'value': 'Theme', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'PREP', 'modifiers': {'value': 'at for on', 'selrestrs': [], 'synrestrs': []}}, {'pos_tag': 'NP', 'modifiers': {'value': 'Asset', 'selrestrs': [], 'synrestrs': []}}]\n",
      "\n",
      "semantics : [{'predicate_value': 'has_possession', 'arguments': [{'type': 'Event', 'value': 'start(E)'}, {'type': 'ThemRole', 'value': 'Agent'}, {'type': 'ThemRole', 'value': 'Theme'}]}, {'predicate_value': 'has_possession', 'arguments': [{'type': 'Event', 'value': 'end(E)'}, {'type': 'ThemRole', 'value': 'Recipient'}, {'type': 'ThemRole', 'value': 'Theme'}]}, {'predicate_value': 'has_possession', 'arguments': [{'type': 'Event', 'value': 'start(E)'}, {'type': 'ThemRole', 'value': 'Recipient'}, {'type': 'ThemRole', 'value': 'Asset'}]}, {'predicate_value': 'has_possession', 'arguments': [{'type': 'Event', 'value': 'end(E)'}, {'type': 'ThemRole', 'value': 'Agent'}, {'type': 'ThemRole', 'value': 'Asset'}]}, {'predicate_value': 'transfer', 'arguments': [{'type': 'Event', 'value': 'during(E)'}, {'type': 'ThemRole', 'value': 'Theme'}]}]\n",
      "\n",
      "\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "#word: \"give\"\n",
    "frames = verbnet.frames(verbnet.vnclass(a[0]))\n",
    "for item in frames:\n",
    "    for key in item.keys():\n",
    "        print(key,\":\", item[key])\n",
    "        print()\n",
    "    print()\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9e24dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['convert-26.6.2',\n",
       " 'crane-40.3.2',\n",
       " 'hurt-40.8.3-1-1',\n",
       " 'meander-47.7',\n",
       " 'roll-51.3.1',\n",
       " 'turn-26.6.1-1']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word1,\":\")\n",
    "verbnet.classids(lemma = word1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2ad297",
   "metadata": {},
   "source": [
    "*Verbs that participate in this alternation include scatter, pump, hang, drizzle, and cram, all of which are verbs that semantically involve a type of placement or covering. Because of their shared syntactic behaviors, these verbs are grouped together in the Spray-‐9.7 class.*\n",
    "\n",
    "Share syntactic behaviors -> grouped together in classes -> check shared classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75ba9ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn : ['convert-26.6.2', 'crane-40.3.2', 'hurt-40.8.3-1-1', 'meander-47.7', 'roll-51.3.1', 'turn-26.6.1-1']\n",
      "twist : ['coil-9.6-1', 'hurt-40.8.3-1-1', 'knead-26.5', 'meander-47.7', 'roll-51.3.1']\n",
      "jump : ['calibratable_cos-45.6-1', 'run-51.3.2']\n"
     ]
    }
   ],
   "source": [
    "print(word1,\":\", verbnet.classids(lemma = word1))\n",
    "print(word2,\":\", verbnet.classids(lemma = word2))\n",
    "print(word3,\":\", verbnet.classids(lemma = word3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87de47",
   "metadata": {},
   "source": [
    "# SimVerb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1fc6e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word1     word2 pos  sv_score        relation\n",
      "0            take    remove   V      6.81        SYNONYMS\n",
      "1            walk     trail   V      4.81      COHYPONYMS\n",
      "2            feed    starve   V      1.49        ANTONYMS\n",
      "3           shine    polish   V      7.80        SYNONYMS\n",
      "4       calculate       add   V      5.98  HYPER/HYPONYMS\n",
      "...           ...       ...  ..       ...             ...\n",
      "3495       impose     cheat   V      1.16            NONE\n",
      "3496        rebel   protest   V      7.64  HYPER/HYPONYMS\n",
      "3497  collaborate  conspire   V      4.23            NONE\n",
      "3498     conspire   protest   V      1.83            NONE\n",
      "3499      protest   release   V      1.16            NONE\n",
      "\n",
      "[3500 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "simverb = pd.read_csv(\"../data/SimVerb-3500.txt\",sep='\\t', header = None)\n",
    "\n",
    "simverb.columns = [\"word1\",\"word2\",\"pos\",\"sv_score\",'relation']\n",
    "\n",
    "print(simverb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a5d913f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         word1     word2  r0  r1  r2  r3  r4  r5  r6  r7  ...  r692  r693  \\\n",
      "0       obtain  exchange   2   1   0   0   0   2   1   4  ...     2     3   \n",
      "1         draw     paint   3   4   2   4   5   3   2   4  ...     5     5   \n",
      "2       choose      pick  -1  -1  -1  -1  -1  -1  -1  -1  ...    -1    -1   \n",
      "3        seize   control  -1  -1  -1  -1  -1  -1  -1  -1  ...    -1    -1   \n",
      "4     disprove      deny  -1  -1  -1  -1  -1  -1  -1  -1  ...    -1    -1   \n",
      "...        ...       ...  ..  ..  ..  ..  ..  ..  ..  ..  ...   ...   ...   \n",
      "3515      save   reserve  -1  -1  -1  -1  -1  -1  -1  -1  ...    -1    -1   \n",
      "3516   clarify    repeat  -1  -1  -1  -1  -1  -1  -1  -1  ...    -1    -1   \n",
      "3517      yell      talk  -1  -1  -1  -1  -1  -1  -1  -1  ...    -1    -1   \n",
      "3518     grant      give  -1  -1  -1  -1  -1  -1  -1  -1  ...    -1    -1   \n",
      "3519      swim   flutter  -1  -1  -1  -1  -1  -1  -1  -1  ...    -1    -1   \n",
      "\n",
      "      r694  r695  r696  r697  r698  r699  r700  r701  \n",
      "0        0     2     2     1     1     1     1     2  \n",
      "1        4     1     3     4     2     2     6     5  \n",
      "2       -1    -1    -1    -1    -1    -1    -1    -1  \n",
      "3       -1    -1    -1    -1    -1    -1    -1    -1  \n",
      "4       -1    -1    -1    -1    -1    -1    -1    -1  \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "3515    -1    -1    -1    -1    -1    -1    -1    -1  \n",
      "3516    -1    -1    -1    -1    -1    -1    -1    -1  \n",
      "3517    -1    -1    -1    -1    -1    -1    -1    -1  \n",
      "3518    -1    -1    -1    -1    -1    -1    -1    -1  \n",
      "3519    -1    -1    -1    -1    -1    -1    -1    -1  \n",
      "\n",
      "[3520 rows x 704 columns]\n"
     ]
    }
   ],
   "source": [
    "simverb_full_ratings = pd.read_csv(\"../data/SimVerb-3520-annotator-ratings.csv\", header = None)\n",
    "# simverb.columns = [\"word1\",\"word2\",\"pos\",\"sv_score\",'relation']\n",
    "indexes = range(0,702, 1)\n",
    "cols = [\"r\"+ str(rater) for rater in indexes]\n",
    "colsets = [\"r\"+ str(rater) for rater in indexes]\n",
    "cols.insert(0, \"word2\")\n",
    "cols.insert(0, \"word1\")\n",
    "simverb_full_ratings.columns = cols\n",
    "print(simverb_full_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88b78311",
   "metadata": {},
   "outputs": [],
   "source": [
    "simverb_ratings = pd.read_csv(\"../data/SimVerb-3500-ratings.csv\")\n",
    "\n",
    "# print(simverb_ratings)\n",
    "\n",
    "simverb_ratings[\"mean_rating\"] = scale_converter(simverb_ratings[['r1','r2','r3','r4','r5','r6','r7','r8','r9','r10']].mean(axis = 1))\n",
    "simverb_ratings[\"sd_rating\"] = simverb_ratings[['r1','r2','r3','r4','r5','r6','r7','r8','r9','r10']].std(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe770a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e87d687",
   "metadata": {},
   "source": [
    "## Background: \n",
    "- Meaning as inherent in word relations, meaning as derived from statistical regularities -> distributional semantics theory of word meaning\n",
    "\n",
    "\n",
    "- Verbs and nouns are conceptually different, which may be reflected in age of acquisition for English speaking babies \n",
    "- Noun bias (see Ch11 from https://langcog.github.io/wordbank-book/categories-syntactic.html)\n",
    "- Nouns seem to be more \"indexical\" in nature, with a given label (usually) mapping directly to a object, or more concrete aspect, while verbs are more relational (Gentner, 1982)\n",
    "- Other considerations: syntactic position, morphology\n",
    "\n",
    "\n",
    "- This difference is also reflected in distributional semantics models\n",
    "- Distributional semantics models as harnessing the co-occurrence statistics to capture word meaning\n",
    "- Variety of models perform well on different tasks, however, recently developed gold standards (simlex, simverb) have shown that their performance greatly differs based on part of speech\n",
    "\n",
    "\n",
    "- What differentiates these two POS in their representation? \n",
    "\n",
    "## Research question:\n",
    "- What is the relationship between syntax and semantics for verb understanding? \n",
    "- How do syntax and semantics interact regarding verb representation?\n",
    "- How do these models reflect our own linguistic processing of verbs?\n",
    "\n",
    "General question: See above ^\n",
    "\n",
    "Research question: Does syntactic and semantic info impact people's performance on human judgement of similarity?\n",
    "\n",
    "-> show specifically these different types of information --> control condition (has syntax but not informative about their meaning representation)\n",
    "\n",
    "-> inter annotater agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b691a7a",
   "metadata": {},
   "source": [
    "Corpus data -> frequencies of ()\n",
    "\n",
    "Google ngrams -> syntactic version (syntgram), checking syntactic frame (counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208acbaf",
   "metadata": {},
   "source": [
    "## Implementation / approach:\n",
    "- Use WordNet and VerbNet as *what* -> syntactic reference point?\n",
    "- POS disambiguation: number of different potential parts of speech for a given word -> entropy of potential POS?\n",
    "- Sense disambiguation: 1) number of different senses, 2) average similarity to other senses\n",
    "- *VerbNet* something with subcat bias?\n",
    "\n",
    "### Other thoughts:\n",
    "- Lemmas and amount of verb frames?\n",
    "- Entailment environment\n",
    "\n",
    "#### Out of the scope of this study:\n",
    "- Comparison between languages with and without noun bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f6707a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cases when word not in WN?\n",
    "\n",
    "def potential_pos(word):\n",
    "    pos = []\n",
    "    for sense in wn.synsets(word):\n",
    "        pos.append(sense.pos())\n",
    "    return Counter(pos)\n",
    "        \n",
    "    \n",
    "def num_v_senses(word):\n",
    "#     print(wn.synsets(word, pos = wn.VERB))\n",
    "    num_senses = len(wn.synsets(word, pos = wn.VERB))\n",
    "#     print(num_senses)\n",
    "    return num_senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27700e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3500/3500 [00:00<00:00, 124118.06it/s]\n",
      "100%|██████████| 3500/3500 [00:00<00:00, 94732.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# simverb[\"w1_pos\"] = simverb['word1'].progress_apply(potential_pos)\n",
    "simverb[\"w1_num_v_senses\"] = simverb['word1'].progress_apply(num_v_senses)\n",
    "# simverb[\"w2_pos\"] = simverb['word2'].progress_apply(potential_pos)\n",
    "simverb[\"w2_num_v_senses\"] = simverb['word2'].progress_apply(num_v_senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e42b92f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3500/3500 [00:01<00:00, 2081.60it/s]\n",
      "100%|██████████| 3500/3500 [00:01<00:00, 2037.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# simverb[\"w1_lemmas\"] = simverb[\"word1\"].progress_apply(get_lemmas)\n",
    "# simverb[\"w2_lemmas\"] = simverb[\"word2\"].progress_apply(get_lemmas)\n",
    "simverb[\"w1_frames\"] = simverb[\"word1\"].progress_apply(get_frames)\n",
    "simverb[\"w2_frames\"] = simverb[\"word2\"].progress_apply(get_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc194d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_ratings = simverb_ratings[[\"word1\", \"word2\",\"mean_rating\",\"sd_rating\"]]\n",
    "\n",
    "# print(simverb_ratings)\n",
    "\n",
    "sv_set = pd.merge(simverb, sv_ratings, how = \"left\", on = [\"word1\", \"word2\"])\n",
    "\n",
    "sv_set.to_csv(\"../data_output/simverb_processed.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3de0c947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word1     word2 pos  sv_score        relation  w1_num_v_senses  \\\n",
      "0            take    remove   V      6.81        SYNONYMS               42   \n",
      "1            walk     trail   V      4.81      COHYPONYMS               10   \n",
      "2            feed    starve   V      1.49        ANTONYMS               12   \n",
      "3           shine    polish   V      7.80        SYNONYMS               10   \n",
      "4       calculate       add   V      5.98  HYPER/HYPONYMS                6   \n",
      "...           ...       ...  ..       ...             ...              ...   \n",
      "3495       impose     cheat   V      1.16            NONE                3   \n",
      "3496        rebel   protest   V      7.64  HYPER/HYPONYMS                2   \n",
      "3497  collaborate  conspire   V      4.23            NONE                2   \n",
      "3498     conspire   protest   V      1.83            NONE                2   \n",
      "3499      protest   release   V      1.16            NONE                3   \n",
      "\n",
      "      w2_num_v_senses                                          w1_frames  \\\n",
      "0                   8  [Basic Transitive, NP-PP, PP-NP, NP-PP, NP-PP-...   \n",
      "1                   5  [Basic Intransitive, PP, NP-PP, NP-PP, NP, NP,...   \n",
      "2                   5                  [Basic Transitive, NP-PP, Dative]   \n",
      "3                   3  [Intransitive, PP, PP, Locative Inversion, The...   \n",
      "4                   6                                               [-1]   \n",
      "...               ...                                                ...   \n",
      "3495                4                                            [NP, S]   \n",
      "3496                3           [Basic Intransitive, PP, PP, TO-INFN-SC]   \n",
      "3497                2           [Basic Intransitive, PP, PP, TO-INFN-SC]   \n",
      "3498                3           [Basic Intransitive, PP, PP, TO-INFN-SC]   \n",
      "3499               10           [Basic Intransitive, PP, PP, TO-INFN-SC]   \n",
      "\n",
      "                                              w2_frames  mean_rating  \\\n",
      "0                      [Basic Transitive, NP-PP, NP-PP]     6.833333   \n",
      "1                         [Basic Transitive, NP-PP, PP]     4.833333   \n",
      "2                 [Transitive, Intransitive, PP, NP-PP]     1.500000   \n",
      "3                                   [Transitive, NP-PP]     7.833333   \n",
      "4     [NP-PP, Simple Reciprocal Transitive, Together...     6.000000   \n",
      "...                                                 ...          ...   \n",
      "3495                         [NP-PP, NP-PP, Transitive]     1.166667   \n",
      "3496           [Basic Intransitive, PP, PP, TO-INFN-SC]     7.666667   \n",
      "3497           [Basic Intransitive, PP, PP, TO-INFN-SC]     4.500000   \n",
      "3498           [Basic Intransitive, PP, PP, TO-INFN-SC]     1.833333   \n",
      "3499                                      [NP-P-ING-OC]     1.166667   \n",
      "\n",
      "      sd_rating  \n",
      "0      1.791957  \n",
      "1      0.875595  \n",
      "2      1.852926  \n",
      "3      1.059350  \n",
      "4      2.118700  \n",
      "...         ...  \n",
      "3495   1.337494  \n",
      "3496   1.646545  \n",
      "3497   2.213594  \n",
      "3498   1.286684  \n",
      "3499   1.059350  \n",
      "\n",
      "[3500 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sv_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "217cd261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(SUBCAT ADL)' '(SUBCAT MP)' '-1' 'ADJP' 'ADJP-PP' 'ADVP-PRED'\n",
      " 'Attribute Object Possessor-Attribute Factoring Alternation'\n",
      " 'Basic Intransitive' 'Basic Transitive' 'Benefactive Alternation'\n",
      " 'Characteristic Property of Instrument' 'Conative' 'Dative' 'FOR-TO-INF'\n",
      " 'HOW-S' 'HOW-TO-INF' 'ING-AC' 'ING-NP-OMIT' 'ING-SC/BE-ING'\n",
      " 'ING-SC/BE-ING-SC' 'Infinitival Copular Clause'\n",
      " 'Instrument Subject Alternation' 'Intransitive'\n",
      " 'Location Subject Alternation' 'Locative Inversion'\n",
      " 'Locative Preposition Drop' 'Locatum Subject Alternation'\n",
      " 'Material/Product Alternation Transitive' 'Middle Construction' 'NP'\n",
      " 'NP-ADJP' 'NP-ADJP-PP' 'NP-ADJP-PRED' 'NP-ADVP-PRED' 'NP-HOW-S'\n",
      " 'NP-HOW-TO-INF' 'NP-ING-SC' 'NP-NP' 'NP-NP-PP' 'NP-NP-PRED' 'NP-P-ING'\n",
      " 'NP-P-ING-AC' 'NP-P-ING-OC' 'NP-P-ING-SC' 'NP-PP' 'NP-PP-PP' 'NP-QUOT'\n",
      " 'NP-S' 'NP-TO-INF-OC' 'NP-TOBE' 'NP-VEN-NP-OMIT' 'NP-WH-S' 'NP-WH-TO-INF'\n",
      " 'NP-WHAT-S' 'NP-WHAT-TO-INF' 'P-ING-SC' 'P-NP-ING' 'P-NP-TO-INF'\n",
      " 'P-POSSING' 'P-WH-S' 'P-WH-TO-INF' 'P-WHAT-S' 'P-WHAT-TO-INF' 'PART-NP'\n",
      " 'POSSING' 'PP' 'PP-HOW-S' 'PP-HOW-TO-INF' 'PP-NP' 'PP-P-WH-S'\n",
      " 'PP-P-WH-TO-INF' 'PP-P-WHAT-S' 'PP-P-WHAT-TO-INF' 'PP-PP' 'PP-QUOT'\n",
      " 'PP-S' 'PP-THAT-S-SUBJUNCT' 'PP-TO-INF-OC' 'PP-WH-S' 'PP-WHAT-S'\n",
      " 'PRO-Arb Object Alternation' 'QUOT' 'Raw Material Subject'\n",
      " 'Reflexive of Appearance' 'S' 'S-SUBJUNCT' 'SEEM-S'\n",
      " 'Simple Reciprocal Intransitive' 'Simple Reciprocal Transitive' 'THAT-S'\n",
      " 'TO-INF-AC' 'TO-INF-SC' 'TO-INFN-SC' 'There-insertion'\n",
      " 'Together Reciprocal Alternation Intransitive'\n",
      " 'Together Reciprocal Alternation Transitive' 'Transitive'\n",
      " 'Understood Reciprocal Object' 'Unintentional Interpretation of Object'\n",
      " 'Unspecified Object' 'Unspecified Reflexive Object' 'WH-S' 'WH-TO-INF'\n",
      " 'WHAT-S' 'WHAT-TO-INF' 'With Preposition Drop']\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "data_frames = np.unique(sv_set[[\"w1_frames\",\"w2_frames\"]].values)\n",
    "\n",
    "unique_frames = []\n",
    "\n",
    "for item in data_frames:\n",
    "    for frame in item:\n",
    "        unique_frames.append(frame)\n",
    "\n",
    "unique_frames = np.unique(unique_frames)\n",
    "print(unique_frames)\n",
    "print(len(unique_frames))\n",
    "\n",
    "# One-hot encoding? Index coding? Number of syntax frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1adbaf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word1     word2 pos  sv_score        relation  w1_num_v_senses  \\\n",
      "0            take    remove   V      6.81        SYNONYMS               42   \n",
      "1            walk     trail   V      4.81      COHYPONYMS               10   \n",
      "2            feed    starve   V      1.49        ANTONYMS               12   \n",
      "3           shine    polish   V      7.80        SYNONYMS               10   \n",
      "4       calculate       add   V      5.98  HYPER/HYPONYMS                6   \n",
      "...           ...       ...  ..       ...             ...              ...   \n",
      "3495       impose     cheat   V      1.16            NONE                3   \n",
      "3496        rebel   protest   V      7.64  HYPER/HYPONYMS                2   \n",
      "3497  collaborate  conspire   V      4.23            NONE                2   \n",
      "3498     conspire   protest   V      1.83            NONE                2   \n",
      "3499      protest   release   V      1.16            NONE                3   \n",
      "\n",
      "      w2_num_v_senses                                          w1_frames  \\\n",
      "0                   8  [Basic Transitive, NP-PP, PP-NP, NP-PP, NP-PP-...   \n",
      "1                   5  [Basic Intransitive, PP, NP-PP, NP-PP, NP, NP,...   \n",
      "2                   5                  [Basic Transitive, NP-PP, Dative]   \n",
      "3                   3  [Intransitive, PP, PP, Locative Inversion, The...   \n",
      "4                   6                                               [-1]   \n",
      "...               ...                                                ...   \n",
      "3495                4                                            [NP, S]   \n",
      "3496                3           [Basic Intransitive, PP, PP, TO-INFN-SC]   \n",
      "3497                2           [Basic Intransitive, PP, PP, TO-INFN-SC]   \n",
      "3498                3           [Basic Intransitive, PP, PP, TO-INFN-SC]   \n",
      "3499               10           [Basic Intransitive, PP, PP, TO-INFN-SC]   \n",
      "\n",
      "                                              w2_frames  mean_rating  \\\n",
      "0                      [Basic Transitive, NP-PP, NP-PP]     6.833333   \n",
      "1                         [Basic Transitive, NP-PP, PP]     4.833333   \n",
      "2                 [Transitive, Intransitive, PP, NP-PP]     1.500000   \n",
      "3                                   [Transitive, NP-PP]     7.833333   \n",
      "4     [NP-PP, Simple Reciprocal Transitive, Together...     6.000000   \n",
      "...                                                 ...          ...   \n",
      "3495                         [NP-PP, NP-PP, Transitive]     1.166667   \n",
      "3496           [Basic Intransitive, PP, PP, TO-INFN-SC]     7.666667   \n",
      "3497           [Basic Intransitive, PP, PP, TO-INFN-SC]     4.500000   \n",
      "3498           [Basic Intransitive, PP, PP, TO-INFN-SC]     1.833333   \n",
      "3499                                      [NP-P-ING-OC]     1.166667   \n",
      "\n",
      "      sd_rating  w1_frame_count  w2_frame_count  relation_index  \n",
      "0      1.791957               6               3               4  \n",
      "1      0.875595              14               3               1  \n",
      "2      1.852926               3               4               0  \n",
      "3      1.059350               6               2               4  \n",
      "4      2.118700               1               6               2  \n",
      "...         ...             ...             ...             ...  \n",
      "3495   1.337494               2               3               3  \n",
      "3496   1.646545               4               4               2  \n",
      "3497   2.213594               4               4               3  \n",
      "3498   1.286684               4               4               3  \n",
      "3499   1.059350               4               1               3  \n",
      "\n",
      "[3500 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "sv_set[\"w1_frame_count\"] = sv_set[\"w1_frames\"].apply(len)\n",
    "sv_set[\"w2_frame_count\"] = sv_set[\"w2_frames\"].apply(len)\n",
    "relations = np.sort(pd.unique(sv_set[\"relation\"]))\n",
    "keys = list(range(0, len(relations)))\n",
    "relation_dict = {relations[i]: keys[i] for i in range(len(relations))}\n",
    "sv_set[\"relation_index\"] = sv_set[\"relation\"].map(relation_dict)\n",
    "print(sv_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a35c021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Full predictors  Senses and Frames    Senses    Frames\n",
      "0         0.262019           0.255672  0.260339  0.283622\n"
     ]
    }
   ],
   "source": [
    "inputs = sv_set[[\"relation_index\",\"w1_frame_count\",\"w2_frame_count\",\"w1_num_v_senses\",\"w2_num_v_senses\"]]\n",
    "\n",
    "targets = sv_set[[\"sd_rating\"]]\n",
    "\n",
    "(train_inputs, test_inputs, train_targets, test_targets) = train_test_split(inputs.to_numpy(), targets.to_numpy(), test_size=0.33)\n",
    "\n",
    "reg = LinearRegression().fit(train_inputs, train_targets)\n",
    "\n",
    "predicted_targets = reg.predict(test_inputs)\n",
    "\n",
    "mse_full = mean_squared_error(test_targets, predicted_targets)\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "inputs = sv_set[[\"w1_frame_count\",\"w2_frame_count\",\"w1_num_v_senses\",\"w2_num_v_senses\"]]\n",
    "\n",
    "targets = sv_set[[\"sd_rating\"]]\n",
    "\n",
    "(train_inputs, test_inputs, train_targets, test_targets) = train_test_split(inputs.to_numpy(), targets.to_numpy(), test_size=0.33)\n",
    "\n",
    "reg = LinearRegression().fit(train_inputs, train_targets)\n",
    "\n",
    "predicted_targets = reg.predict(test_inputs)\n",
    "\n",
    "mse_frames_senses = mean_squared_error(test_targets, predicted_targets)\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "inputs = sv_set[[\"w1_num_v_senses\",\"w2_num_v_senses\"]]\n",
    "\n",
    "targets = sv_set[[\"sd_rating\"]]\n",
    "\n",
    "(train_inputs, test_inputs, train_targets, test_targets) = train_test_split(inputs.to_numpy(), targets.to_numpy(), test_size=0.33)\n",
    "\n",
    "reg = LinearRegression().fit(train_inputs, train_targets)\n",
    "\n",
    "predicted_targets = reg.predict(test_inputs)\n",
    "\n",
    "mse_senses = mean_squared_error(test_targets, predicted_targets)\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "inputs = sv_set[[\"w1_frame_count\",\"w2_frame_count\"]]\n",
    "\n",
    "targets = sv_set[[\"sd_rating\"]]\n",
    "\n",
    "(train_inputs, test_inputs, train_targets, test_targets) = train_test_split(inputs.to_numpy(), targets.to_numpy(), test_size=0.33)\n",
    "\n",
    "reg = LinearRegression().fit(train_inputs, train_targets)\n",
    "\n",
    "predicted_targets = reg.predict(test_inputs)\n",
    "\n",
    "mse_frames = mean_squared_error(test_targets, predicted_targets)\n",
    "\n",
    "results_df = pd.DataFrame({\"Full predictors\": [mse_full], \"Senses and Frames\": [mse_frames_senses], 'Senses': [mse_senses], 'Frames': [mse_frames]})\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5549019123591784\n"
     ]
    }
   ],
   "source": [
    "# Train memory-based learner?\n",
    "\n",
    "inputs = sv_set[[\"relation_index\",\"w1_frame_count\",\"w2_frame_count\",\"w1_num_v_senses\",\"w2_num_v_senses\"]]\n",
    "\n",
    "targets = sv_set[[\"sd_rating\"]]\n",
    "\n",
    "(train_inputs, test_inputs, train_targets, test_targets) = train_test_split(inputs.to_numpy(), targets.to_numpy(), test_size=0.33)\n",
    "\n",
    "svr_rbf = SVR(kernel=\"rbf\", C=100, gamma=0.1, epsilon=0.1)\n",
    "\n",
    "svr_rbf_fitted = svr_rbf.fit(train_inputs, train_targets.ravel())\n",
    "\n",
    "predicted_targets = svr_rbf_fitted.predict(test_inputs)\n",
    "print(mean_squared_error(predicted_targets, test_targets.ravel()))\n",
    "\n",
    "# parameters = {\"n_neighbors\": [3,5,7,9],\n",
    "#               \"weights\": [\"uniform\", \"distance\"],\n",
    "#               \"algorithm\": [\"auto\",\"ball_tree\",\"kd_tree\", \"brute\"],\n",
    "#               \"metric\": [\"euclidean\",\"manhattan\",\"minkowski\"]}\n",
    "\n",
    "\n",
    "# knclf = KNeighborsClassifier()\n",
    "\n",
    "# gridsearch = GridSearchCV(knclf,\n",
    "#                           parameters,\n",
    "#                           cv = 5)\n",
    "\n",
    "# # print(test_targets.shape)\n",
    "\n",
    "# knclf_fitted = gridsearch.fit(train_inputs, train_targets.ravel())\n",
    "\n",
    "# predicted_targets = knclf_fitted.predict(test_inputs)\n",
    "# print(classification_report(test_targets, predicted_targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac2f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inter-annotator agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80188f",
   "metadata": {},
   "source": [
    "# Todo:\n",
    "Checking inter-annotater agreement, seeing how added context impacts the inter-annotater agreement.\n",
    "\n",
    "Syntgram / triarcs -> check Rachel's grant (3.1.1)\n",
    "- Syntactic frames of the different words\n",
    "- Overlap measure -> shared frames, bias as majority frame -> more semantically related to other verbs of this type with same bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('linc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2eee6f59c8024d8f9ce466600c0d127c15ffd837f8ce65dafc8ae680f3ddcf5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
