{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c1ded2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "import os\n",
    "from collections import Counter\n",
    "from nltk.corpus import verbnet\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c1f60a",
   "metadata": {},
   "source": [
    "# WordNet demo\n",
    "\n",
    "Choose some words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e8a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = \"turn\"\n",
    "word2 = \"twist\"\n",
    "word3 = \"jump\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e1510",
   "metadata": {},
   "source": [
    "Synsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d61cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synsets for turn\n",
      "[Synset('bend.n.01'), Synset('turn.n.02'), Synset('turn.n.03'), Synset('turn.n.04'), Synset('turning.n.04'), Synset('turn.n.06'), Synset('twist.n.13'), Synset('go.n.01'), Synset('turn.n.09'), Synset('act.n.04'), Synset('turn.n.11'), Synset('turn.n.12'), Synset('turn.v.01'), Synset('change_state.v.01'), Synset('become.v.02'), Synset('turn.v.04'), Synset('change_by_reversal.v.01'), Synset('turn.v.06'), Synset('turn.v.07'), Synset('turn.v.08'), Synset('turn.v.09'), Synset('turn.v.10'), Synset('turn.v.11'), Synset('plow.v.01'), Synset('turn.v.13'), Synset('turn.v.14'), Synset('twist.v.10'), Synset('turn.v.16'), Synset('turn.v.17'), Synset('turn.v.18'), Synset('turn.v.19'), Synset('turn.v.20'), Synset('flex.v.05'), Synset('turn.v.22'), Synset('turn.v.23'), Synset('call_on.v.01'), Synset('sour.v.01'), Synset('turn.v.26')]\n",
      "\n",
      "Synsets for turn filtered just to verb POS\n",
      "[Synset('turn.v.01'), Synset('change_state.v.01'), Synset('become.v.02'), Synset('turn.v.04'), Synset('change_by_reversal.v.01'), Synset('turn.v.06'), Synset('turn.v.07'), Synset('turn.v.08'), Synset('turn.v.09'), Synset('turn.v.10'), Synset('turn.v.11'), Synset('plow.v.01'), Synset('turn.v.13'), Synset('turn.v.14'), Synset('twist.v.10'), Synset('turn.v.16'), Synset('turn.v.17'), Synset('turn.v.18'), Synset('turn.v.19'), Synset('turn.v.20'), Synset('flex.v.05'), Synset('turn.v.22'), Synset('turn.v.23'), Synset('call_on.v.01'), Synset('sour.v.01'), Synset('turn.v.26')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Synsets for\", word1)\n",
    "print(wn.synsets(word1))\n",
    "print()\n",
    "print(\"Synsets for\",word1,\"filtered just to verb POS\")\n",
    "print(wn.synsets(word1, pos = wn.VERB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22702d0",
   "metadata": {},
   "source": [
    "Just for now, selecting the first synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0c89a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_syn = wn.synsets(word1, pos = wn.VERB)[0]\n",
    "w2_syn = wn.synsets(word2, pos = wn.VERB)[0]\n",
    "w3_syn = wn.synsets(word3, pos = wn.VERB)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ba3a2",
   "metadata": {},
   "source": [
    "# Verb frames:\n",
    "\n",
    "For the synsets' lemma, it has a specific amount of verb frames. It generally seems to be the same amount per synset for each lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519508d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma('turn.v.01.turn') [1, 2, 4] 3\n",
      "Something turn | Somebody turn | Something is turning PP\n",
      "------------------------------\n",
      "Lemma('writhe.v.01.writhe') [1, 2] 2\n",
      "Something writhe | Somebody writhe\n",
      "Lemma('writhe.v.01.wrestle') [1, 2] 2\n",
      "Something wrestle | Somebody wrestle\n",
      "Lemma('writhe.v.01.wriggle') [1, 2] 2\n",
      "Something wriggle | Somebody wriggle\n",
      "Lemma('writhe.v.01.worm') [1, 2] 2\n",
      "Something worm | Somebody worm\n",
      "Lemma('writhe.v.01.squirm') [1, 2] 2\n",
      "Something squirm | Somebody squirm\n",
      "Lemma('writhe.v.01.twist') [1, 2] 2\n",
      "Something twist | Somebody twist\n",
      "------------------------------\n",
      "Lemma('jump.v.01.jump') [1, 2, 22] 3\n",
      "Something jump | Somebody jump | Somebody jump PP\n",
      "Lemma('jump.v.01.leap') [1, 2, 22] 3\n",
      "Something leap | Somebody leap | Somebody leap PP\n",
      "Lemma('jump.v.01.bound') [1, 2, 22] 3\n",
      "Something bound | Somebody bound | Somebody bound PP\n",
      "Lemma('jump.v.01.spring') [1, 2, 22] 3\n",
      "Something spring | Somebody spring | Somebody spring PP\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for lemma in w1_syn.lemmas():\n",
    "    print(lemma, lemma.frame_ids(), len(lemma.frame_ids()))\n",
    "    print(\" | \".join(lemma.frame_strings()))\n",
    "print(\"------------------------------\")\n",
    "\n",
    "for lemma in w2_syn.lemmas():\n",
    "    print(lemma, lemma.frame_ids(), len(lemma.frame_ids()))\n",
    "    print(\" | \".join(lemma.frame_strings()))\n",
    "print(\"------------------------------\")\n",
    "\n",
    "for lemma in w3_syn.lemmas():\n",
    "    print(lemma, lemma.frame_ids(), len(lemma.frame_ids()))\n",
    "    print(\" | \".join(lemma.frame_strings()))\n",
    "print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880368de",
   "metadata": {},
   "source": [
    "# Multiple similarity metrics: \n",
    "\n",
    "Path similarity\n",
    "\n",
    "Leacock-Chodorow Similarity\n",
    "\n",
    "Wu-Palmer similarity\n",
    "\n",
    "Resnik similarity\n",
    "\n",
    "Jiang-Conrath similarity\n",
    "\n",
    "Lin Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f0f84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path similarity: 0.3333333333333333\n",
      "Lch similarity: 2.159484249353372\n",
      "Wup similarity: 0.3333333333333333\n",
      "Res similarity: 4.692755582239643\n",
      "JCN similarity: 0.12831564565996478\n",
      "Lin similarity: 0.546342873109817\n"
     ]
    }
   ],
   "source": [
    "print(\"Path similarity:\", w1_syn.path_similarity(w2_syn))\n",
    "\n",
    "print(\"Lch similarity:\",w1_syn.lch_similarity(w2_syn))\n",
    "\n",
    "print(\"Wup similarity:\",w1_syn.wup_similarity(w2_syn))\n",
    "\n",
    "print(\"Res similarity:\",w1_syn.res_similarity(w2_syn, brown_ic))\n",
    "\n",
    "print(\"JCN similarity:\",w1_syn.jcn_similarity(w2_syn, brown_ic))\n",
    "\n",
    "print(\"Lin similarity:\",w1_syn.lin_similarity(w2_syn, brown_ic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c44707",
   "metadata": {},
   "source": [
    "# VerbNet:\n",
    "\n",
    "http://verbs.colorado.edu/~kipper/Papers/dissertation.pdf\n",
    "\n",
    "http://verbs.colorado.edu/verb-index/VerbNet_Guidelines.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5091b964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['give-13.1-1']\n",
      "lemmas ['give', 'hock', 'rent', 'sell', 'lease', 'pawn']\n",
      "vnclass <Element 'VNSUBCLASS' at 0x0000019979B2C4F0>\n",
      "Sub-classes []\n"
     ]
    }
   ],
   "source": [
    "a = verbnet.classids(lemma = \"give\")\n",
    "print(a)\n",
    "\n",
    "print(\"lemmas\",verbnet.lemmas(a[0]))\n",
    "\n",
    "print(\"vnclass\",verbnet.vnclass(a[0]))\n",
    "\n",
    "print(\"Sub-classes\", verbnet.subclasses(verbnet.vnclass(a[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cd70c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classid(verb):\n",
    "    # print(verb)\n",
    "    classid = verbnet.classids(lemma = verb)\n",
    "    # print(classid)\n",
    "    return classid\n",
    "    \n",
    "def get_lemmas(verb):\n",
    "    classid = get_classid(verb)\n",
    "    if len(classid) > 0:\n",
    "        lemmas = verbnet.lemmas(classid[0])\n",
    "        return lemmas\n",
    "    else:\n",
    "        return \"-1\"\n",
    "\n",
    "def get_frames(verb):\n",
    "    classid = get_classid(verb)\n",
    "    if len(classid) > 0:\n",
    "        frames = []\n",
    "        for item in verbnet.frames(classid[0]):\n",
    "            # print(item)\n",
    "            frames.append(item[\"description\"][\"primary\"])\n",
    "        return frames\n",
    "    else:\n",
    "        return [\"-1\"]\n",
    "\n",
    "def get_unique_frames(classid):\n",
    "    frames = []\n",
    "    for item in verbnet.frames(classid[0]):\n",
    "        # print(item)\n",
    "        frames.append(item[\"description\"][\"primary\"])\n",
    "    return pd.unique(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c372c702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['get-13.5.1']\n",
      "['attain', 'book', 'buy', 'call', 'catch', 'charter', 'choose', 'conserve', 'find', 'gather', 'hire', 'lease', 'order', 'phone', 'pick', 'pluck', 'procure', 'pull', 'reach', 'rent', 'reserve', 'secure', 'shoot', 'slaughter', 'vote', 'win']\n",
      "['Basic Transitive', 'NP-PP', 'NP-PP', 'Benefactive Alternation', 'NP-PP', 'NP', 'NP-PP-PP']\n"
     ]
    }
   ],
   "source": [
    "step1 = get_classid(\"catch\")\n",
    "print(step1)\n",
    "\n",
    "step2a = get_lemmas(step1)\n",
    "print(step2a)\n",
    "\n",
    "step2b = get_frames(step1)\n",
    "print(step2b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a677f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word: \"give\"\n",
    "frames = verbnet.frames(verbnet.vnclass(a[0]))\n",
    "for item in frames:\n",
    "    for key in item.keys():\n",
    "        print(key,\":\", item[key])\n",
    "        print()\n",
    "    print()\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e24dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['convert-26.6.2',\n",
       " 'crane-40.3.2',\n",
       " 'hurt-40.8.3-1-1',\n",
       " 'meander-47.7',\n",
       " 'roll-51.3.1',\n",
       " 'turn-26.6.1-1']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(word1,\":\")\n",
    "verbnet.classids(lemma = word1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2ad297",
   "metadata": {},
   "source": [
    "*Verbs that participate in this alternation include scatter, pump, hang, drizzle, and cram, all of which are verbs that semantically involve a type of placement or covering. Because of their shared syntactic behaviors, these verbs are grouped together in the Spray-‐9.7 class.*\n",
    "\n",
    "Share syntactic behaviors -> grouped together in classes -> check shared classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75ba9ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn : ['convert-26.6.2', 'crane-40.3.2', 'hurt-40.8.3-1-1', 'meander-47.7', 'roll-51.3.1', 'turn-26.6.1-1']\n",
      "twist : ['coil-9.6-1', 'hurt-40.8.3-1-1', 'knead-26.5', 'meander-47.7', 'roll-51.3.1']\n",
      "jump : ['calibratable_cos-45.6-1', 'run-51.3.2']\n"
     ]
    }
   ],
   "source": [
    "print(word1,\":\", verbnet.classids(lemma = word1))\n",
    "print(word2,\":\", verbnet.classids(lemma = word2))\n",
    "print(word3,\":\", verbnet.classids(lemma = word3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87de47",
   "metadata": {},
   "source": [
    "# SimVerb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1fc6e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            word1     word2 pos  sv_score        relation\n",
      "0            take    remove   V      6.81        SYNONYMS\n",
      "1            walk     trail   V      4.81      COHYPONYMS\n",
      "2            feed    starve   V      1.49        ANTONYMS\n",
      "3           shine    polish   V      7.80        SYNONYMS\n",
      "4       calculate       add   V      5.98  HYPER/HYPONYMS\n",
      "...           ...       ...  ..       ...             ...\n",
      "3495       impose     cheat   V      1.16            NONE\n",
      "3496        rebel   protest   V      7.64  HYPER/HYPONYMS\n",
      "3497  collaborate  conspire   V      4.23            NONE\n",
      "3498     conspire   protest   V      1.83            NONE\n",
      "3499      protest   release   V      1.16            NONE\n",
      "\n",
      "[3500 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "simverb = pd.read_csv(\"../data/SimVerb-3500.txt\",sep='\\t', header = None)\n",
    "\n",
    "simverb.columns = [\"word1\",\"word2\",\"pos\",\"sv_score\",'relation']\n",
    "\n",
    "print(simverb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87d687",
   "metadata": {},
   "source": [
    "## Background: \n",
    "- Meaning as inherent in word relations, meaning as derived from statistical regularities -> distributional semantics theory of word meaning\n",
    "\n",
    "\n",
    "- Verbs and nouns are conceptually different, which may be reflected in age of acquisition for English speaking babies \n",
    "- Noun bias (see Ch11 from https://langcog.github.io/wordbank-book/categories-syntactic.html)\n",
    "- Nouns seem to be more \"indexical\" in nature, with a given label (usually) mapping directly to a object, or more concrete aspect, while verbs are more relational (Gentner, 1982)\n",
    "- Other considerations: syntactic position, morphology\n",
    "\n",
    "\n",
    "- This difference is also reflected in distributional semantics models\n",
    "- Distributional semantics models as harnessing the co-occurrence statistics to capture word meaning\n",
    "- Variety of models perform well on different tasks, however, recently developed gold standards (simlex, simverb) have shown that their performance greatly differs based on part of speech\n",
    "\n",
    "\n",
    "- What differentiates these two POS in their representation? \n",
    "\n",
    "## Research question:\n",
    "- What is the relationship between syntax and semantics for verb understanding? \n",
    "- How do syntax and semantics interact regarding verb representation?\n",
    "- How do these models reflect our own linguistic processing of verbs?\n",
    "\n",
    "General question: See above ^\n",
    "\n",
    "Research question: Does syntactic and semantic info impact people's performance on human judgement of similarity?\n",
    "\n",
    "-> show specifically these different types of information --> control condition (has syntax but not informative about their meaning representation)\n",
    "\n",
    "-> inter annotater agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b691a7a",
   "metadata": {},
   "source": [
    "Corpus data -> frequencies of ()\n",
    "\n",
    "Google ngrams -> syntactic version (syntgram), checking syntactic frame (counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208acbaf",
   "metadata": {},
   "source": [
    "## Implementation / approach:\n",
    "- Use WordNet and VerbNet as *what* -> syntactic reference point?\n",
    "- POS disambiguation: number of different potential parts of speech for a given word -> entropy of potential POS?\n",
    "- Sense disambiguation: 1) number of different senses, 2) average similarity to other senses\n",
    "- *VerbNet* something with subcat bias?\n",
    "\n",
    "### Other thoughts:\n",
    "- Lemmas and amount of verb frames?\n",
    "- Entailment environment\n",
    "\n",
    "#### Out of the scope of this study:\n",
    "- Comparison between languages with and without noun bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f6707a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cases when word not in WN?\n",
    "\n",
    "def potential_pos(word):\n",
    "    pos = []\n",
    "    for sense in wn.synsets(word):\n",
    "        pos.append(sense.pos())\n",
    "    return Counter(pos)\n",
    "        \n",
    "    \n",
    "def num_v_senses(word):\n",
    "#     print(wn.synsets(word, pos = wn.VERB))\n",
    "    num_senses = len(wn.synsets(word, pos = wn.VERB))\n",
    "#     print(num_senses)\n",
    "    return num_senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27700e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3500/3500 [00:01<00:00, 1848.36it/s]\n",
      "100%|██████████| 3500/3500 [00:00<00:00, 16381.31it/s]\n",
      "100%|██████████| 3500/3500 [00:00<00:00, 11480.94it/s]\n",
      "100%|██████████| 3500/3500 [00:00<00:00, 16045.28it/s]\n"
     ]
    }
   ],
   "source": [
    "simverb[\"w1_pos\"] = simverb['word1'].progress_apply(potential_pos)\n",
    "simverb[\"w1_num_v_senses\"] = simverb['word1'].progress_apply(num_v_senses)\n",
    "simverb[\"w2_pos\"] = simverb['word2'].progress_apply(potential_pos)\n",
    "simverb[\"w2_num_v_senses\"] = simverb['word2'].progress_apply(num_v_senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e42b92f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3500/3500 [00:04<00:00, 711.88it/s]\n",
      "100%|██████████| 3500/3500 [00:05<00:00, 635.96it/s]\n",
      "100%|██████████| 3500/3500 [00:07<00:00, 489.81it/s]\n",
      "100%|██████████| 3500/3500 [00:07<00:00, 487.52it/s]\n"
     ]
    }
   ],
   "source": [
    "simverb[\"w1_lemmas\"] = simverb[\"word1\"].progress_apply(get_lemmas)\n",
    "simverb[\"w2_lemmas\"] = simverb[\"word2\"].progress_apply(get_lemmas)\n",
    "simverb[\"w1_frames\"] = simverb[\"word1\"].progress_apply(get_frames)\n",
    "simverb[\"w2_frames\"] = simverb[\"word2\"].progress_apply(get_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc194d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "simverb.to_csv(\"../data_output/simverb_processed.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['take', 'walk', 'feed', 'shine', 'calculate', 'cheat', 'pardon',\n",
       "       'smell', 'plow', 'believe', 'tap', 'condemn', 'crunch', 'erode',\n",
       "       'try', 'tear', 'replace', 'respond', 'rationalize', 'laugh',\n",
       "       'attack', 'descend', 'decompose', 'miss', 'yell', 'feel',\n",
       "       'connect', 'decay', 'protect', 'bake', 'remove', 'describe',\n",
       "       'drive', 'build', 'cover', 'dislike', 'forget', 'comprehend',\n",
       "       'reflect', 'defeat', 'know', 'remind', 'go', 'produce',\n",
       "       'recommend', 'shake', 'accomplish', 'ask', 'gather', 'bend',\n",
       "       'jump', 'agree', 'give', 'kill', 'carry', 'sing', 'dismay', 'shun',\n",
       "       'hurt', 'prefer', 'cook', 'reprimand', 'break', 'hit', 'wrap',\n",
       "       'upset', 'show', 'accuse', 'hate', 'pounce', 'respect', 'sell',\n",
       "       'put', 'charge', 'melt', 'flap', 'die', 'pull', 'hitch', 'live',\n",
       "       'sow', 'destroy', 'obtain', 'buy', 'deposit', 'rise', 'pray',\n",
       "       'rescue', 'succeed', 'look', 'delay', 'color', 'get', 'drink',\n",
       "       'treat', 'dump', 'learn', 'compete', 'beat', 'thaw', 'kidnap',\n",
       "       'gulp', 'think', 'say', 'tend', 'see', 'preview', 'kick', 'claim',\n",
       "       'confuse', 'want', 'veer', 'persuade', 'arrive', 'skip', 'talk',\n",
       "       'perform', 'wipe', 'decline', 'determine', 'sting', 'search',\n",
       "       'disprove', 'disbelieve', 'lean', 'control', 'alter', 'disturb',\n",
       "       'seem', 'repeat', 'compose', 'justify', 'separate', 'disintegrate',\n",
       "       'have', 'run', 'reap', 'rub', 'finish', 'swap', 'annoy',\n",
       "       'deteriorate', 'hike', 'compute', 'assault', 'inhale', 'sneak',\n",
       "       'brush', 'create', 'travel', 'desire', 'hide', 'increase', 'boom',\n",
       "       'fall', 'hold', 'implode', 'sprain', 'regret', 'flee', 'soak',\n",
       "       'accept', 'add', 'save', 'bring', 'spin', 'overflow', 'offend',\n",
       "       'start', 'spoil', 'weave', 'prepare', 'pretend', 'lose', 'hunt',\n",
       "       'let', 'tug', 'dive', 'dance', 'whisper', 'salute', 'become',\n",
       "       'scare', 'sway', 'float', 'move', 'leave', 'clench', 'concentrate',\n",
       "       'suppose', 'split', 'receive', 'begin', 'call', 'ridicule',\n",
       "       'associate', 'entertain', 'reply', 'evict', 'crackle', 'sew',\n",
       "       'reject', 'hurry', 'defend', 'convince', 'lower', 'enjoy',\n",
       "       'introduce', 'remark', 'sit', 'combine', 'appear', 'smear',\n",
       "       'insult', 'aggravate', 'flow', 'play', 'demand', 'drip', 'confess',\n",
       "       'remember', 'sink', 'tell', 'fade', 'abuse', 'fly', 'boil',\n",
       "       'vacate', 'keep', 'testify', 'yawn', 'make', 'grill', 'grab',\n",
       "       'smoke', 'reappear', 'help', 'fight', 'crawl', 'win', 'leap',\n",
       "       'strike', 'blend', 'meet', 'climb', 'burn', 'borrow', 'unload',\n",
       "       'hear', 'doze', 'stab', 'grasp', 'join', 'deny', 'define',\n",
       "       'triumph', 'stop', 'realize', 'guess', 'drag', 'spell', 'gain',\n",
       "       'forgive', 'relax', 'jerk', 'wear', 'waste', 'bury', 'frustrate',\n",
       "       'come', 'wait', 'burst', 'portray', 'steal', 'transplant', 'speak',\n",
       "       'punish', 'solve', 'organize', 'disperse', 'toast', 'haunt',\n",
       "       'admit', 'stay', 'slide', 'scream', 'permit', 'choke', 'engage',\n",
       "       'sprinkle', 'do', 'develop', 'supply', 'earn', 'dunk', 'seize',\n",
       "       'ponder', 'rap', 'change', 'prohibit', 'choose', 'survive',\n",
       "       'crash', 'release', 'decrease', 'push', 'drift', 'mow', 'rinse',\n",
       "       'visit', 'print', 'dismiss', 'express', 'glance', 'doubt', 'lie',\n",
       "       'scribble', 'comfort', 'sweat', 'exist', 'strive', 'perceive',\n",
       "       'squeeze', 'stretch', 'adjourn', 'soothe', 'blow', 'return',\n",
       "       'teach', 'inspect', 'demolish', 'gamble', 'understand', 'console',\n",
       "       'pay', 'deliver', 'restore', 'watch', 'perspire', 'judge', 'nag',\n",
       "       'listen', 'retreat', 'assume', 'acknowledge', 'obey', 'stain',\n",
       "       'tumble', 'please', 'renounce', 'participate', 'snap', 'toss',\n",
       "       'diminish', 'betray', 'slurp', 'humiliate', 'tickle', 'ride',\n",
       "       'greet', 'prosecute', 'invent', 'squeak', 'avoid', 'divide',\n",
       "       'spank', 'sip', 'crave', 'bother', 'haul', 'draw', 'achieve',\n",
       "       'taste', 'read', 'degrade', 'attempt', 'polish', 'mimic', 'grind',\n",
       "       'need', 'yearn', 'snuggle', 'plead', 'neglect', 'slay',\n",
       "       'originate', 'prosper', 'attend', 'allow', 'practice', 'find',\n",
       "       'rip', 'hoot', 'mend', 'suggest', 'overwhelm', 'amuse', 'follow',\n",
       "       'spend', 'fling', 'update', 'shrink', 'fail', 'rejoice', 'disown',\n",
       "       'debate', 'unite', 'defrost', 'knit', 'scratch', 'stamp', 'ignore',\n",
       "       'exchange', 'compound', 'bleach', 'enter', 'poach', 'overcome',\n",
       "       'prove', 'detach', 'assist', 'chew', 'squeal', 'spill', 'acquire',\n",
       "       'correct', 'remain', 'blame', 'flip', 'glide', 'swim', 'ascend',\n",
       "       'flush', 'rearrange', 'stumble', 'smash', 'wash', 'excuse',\n",
       "       'complain', 'punch', 'marry', 'explain', 'frighten', 'whistle',\n",
       "       'wreck', 'arrest', 'snooze', 'conquer', 'catch', 'capture',\n",
       "       'fasten', 'strain', 'tease', 'excel', 'shatter', 'breathe',\n",
       "       'accumulate', 'wiggle', 'vary', 'tow', 'urge', 'heal', 'set',\n",
       "       'jog', 'touch', 'loosen', 'tote', 'reduce', 'hop', 'argue',\n",
       "       'incline', 'kneel', 'stare', 'snore', 'beware', 'pick',\n",
       "       'disappear', 'like', 'multiply', 'scold', 'shuffle', 'use',\n",
       "       'collect', 'whip', 'perish', 'affect', 'fix', 'evaluate', 'glare',\n",
       "       'lead', 'blur', 'irritate', 'swear', 'squint', 'result', 'be',\n",
       "       'hypnotize', 'despair', 'beg', 'pelt', 'pinch', 'retain',\n",
       "       'magnify', 'differ', 'send', 'notify', 'embarrass', 'cry', 'flex',\n",
       "       'grant', 'command', 'abduct', 'broil', 'disallow', 'reproduce',\n",
       "       'stray', 'bump', 'examine', 'presume', 'pop', 'explode', 'wander',\n",
       "       'pour', 'inform', 'repair', 'crush', 'adore', 'usurp', 'disguise',\n",
       "       'observe', 'cough', 'mistreat', 'depart', 'design', 'knock',\n",
       "       'throw', 'interrupt', 'pluck', 'advise', 'surprise', 'spring',\n",
       "       'review', 'vanish', 'fit', 'disappoint', 'forbid', 'dissolve',\n",
       "       'slither', 'discover', 'fill', 'educate', 'hustle', 'cast',\n",
       "       'criticize', 'lick', 'slap', 'sniff', 'decide', 'slip', 'lounge',\n",
       "       'bluff', 'sneeze', 'dip', 'predict', 'hamper', 'stir', 'hesitate',\n",
       "       'wag', 'depend', 'advance', 'roam', 'tan', 'pause', 'swallow',\n",
       "       'direct', 'warn', 'recruit', 'decorate', 'chop', 'suspect', 'aim',\n",
       "       'duplicate', 'annihilate', 'grow', 'holler', 'steer', 'hope',\n",
       "       'promise', 'turn', 'munch', 'integrate', 'crack', 'dominate',\n",
       "       'giggle', 'despise', 'admire', 'rely', 'fold', 'request', 'bounce',\n",
       "       'seek', 'buzz', 'worry', 'announce', 'lay', 'instruct', 'deceive',\n",
       "       'mix', 'chase', 'cuddle', 'hang', 'analyze', 'glow', 'dig',\n",
       "       'exhale', 'refrain', 'discourage', 'spread', 'lift', 'freeze',\n",
       "       'discuss', 'refuse', 'croak', 'poise', 'hug', 'flutter', 'amaze',\n",
       "       'smother', 'scramble', 'stand', 'tire', 'drain', 'attach', 'bound',\n",
       "       'aid', 'tie', 'strip', 'stink', 'limp', 'disgust', 'rebel',\n",
       "       'count', 'yield', 'elect', 'deal', 'repress', 'select', 'kiss',\n",
       "       'overpower', 'ban', 'imitate', 'write', 'weep', 'erupt', 'attract',\n",
       "       'inquire', 'trail', 'reach', 'rush', 'imagine', 'swoon', 'toil',\n",
       "       'lend', 'rattle', 'dash', 'drown', 'swing', 'struggle', 'reel',\n",
       "       'happen', 'recycle', 'snatch', 'object', 'operate', 'enrage',\n",
       "       'shift', 'purchase', 'shove', 'evacuate', 'rob', 'suck', 'ache',\n",
       "       'spare', 'raise', 'foil', 'shoot', 'hatch', 'spray', 'frame',\n",
       "       'shiver', 'launch', 'bite', 'subtract', 'wake', 'awake', 'drench',\n",
       "       'tread', 'clarify', 'graze', 'dare', 'bumble', 'grate', 'concern',\n",
       "       'address', 'slice', 'sue', 'block', 'spawn', 'accelerate', 'blush',\n",
       "       'graduate', 'press', 'mean', 'shut', 'prick', 'embrace', 'recall',\n",
       "       'angle', 'reserve', 'damn', 'vomit', 'cruise', 'belong', 'own',\n",
       "       'possess', 'register', 'verify', 'invite', 'encourage', 'promote',\n",
       "       'misspend', 'pass', 'serve', 'apply', 'exploit', 'nullify',\n",
       "       'invalidate', 'involve', 'include', 'pup', 'surpass', 'exceed',\n",
       "       'adopt', 'bet', 'submit', 'bow', 'dispose', 'bias', 'tackle',\n",
       "       'face', 'handle', 'approach', 'secure', 'insure', 'ensure',\n",
       "       'discharge', 'retire', 'withdraw', 'cope', 'manage', 'care',\n",
       "       'mind', 'bargain', 'settle', 'intend', 'commit', 'devote',\n",
       "       'restrict', 'limit', 'work', 'cooperate', 'abstain', 'approve',\n",
       "       'enforce', 'impose', 'collaborate', 'conspire', 'protest',\n",
       "       'starve', 'pat', 'hum', 'intoxicate', 'paint', 'escape', 'fry',\n",
       "       'nap', 'award', 'smudge', 'communicate', 'construct', 'bless',\n",
       "       'tarnish', 'celebrate', 'disagree', 'crochet', 'quench', 'wed',\n",
       "       'barter', 'disregard', 'soar', 'roar', 'sob', 'breed', 'corrupt',\n",
       "       'trim', 'adorn', 'chuck', 'flash', 'splash', 'study', 'stew',\n",
       "       'bear', 'chirp', 'duck', 'certify', 'impersonate', 'boost',\n",
       "       'litter', 'outnumber', 'matter', 'risk', 'capitulate', 'acquit',\n",
       "       'free', 'concur', 'dedicate', 'forbear'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_verbs = pd.unique(pd.concat([simverb[\"word1\"],simverb[\"word2\"]]))\n",
    "\n",
    "unique_verbs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db80188f",
   "metadata": {},
   "source": [
    "# Todo:\n",
    "Checking inter-annotater agreement, seeing how added context impacts the inter-annotater agreement.\n",
    "\n",
    "Is there a relationship between that and the WordNet and verbnet measures?\n",
    "\n",
    "Syntgram / triarcs -> check Rachel's grant (3.1.1)\n",
    "- Syntactic frames of the different words\n",
    "- Overlap measure -> shared frames, bias as majority frame -> more semantically related to other verbs of this type with same bias\n",
    "- Goldberg and orwant 2013 (done)\n",
    "- Lenci DSM paper (done)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linc",
   "language": "python",
   "name": "linc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
